```table-of-contents
```
# Thread and Multithread
***Thread*** là một luồng được lên lịch running bởi OS.
***Thread*** tồn tại trong các process, mỗi thread sẽ có một vùng nhớ riêng bao gồm các stack, register để hoạt động.
Các thread trong cùng một process sẽ chia sẻ resource, memory, read và write trên cùng một địa chỉ.

Trong hệ điều hành, có 2 loại thread riêng biệt:
* `User-level thread`: là các thread do user chủ động tạo ra, run và kill
* `Kernel-level thread`: là các thread ở low-level, được handle bởi os
Các thread của python đều là các `User-level thread`.

## Multithread

***Multithread***: là việc chạy nhiều thread cùng lúc để thực hiện 1 hay nhiều tác vụ khác nhau.

Một bộ xử lý có 1 core có thể xử lý đa luồng, processor core có thể ***switch context*** rất nhanh giữa các luồng. Việc ***switch context*** diễn ra rất nhanh => cảm tưởng như nhiều thread đang cùng chạy song song, nhưng bản chất ***1 core chỉ đang xử lý 1 thread tại 1 thời điểm, nó sẽ switch sang xử lý thread khác khi thread hiện tại đang waitting IO hoặc cần chờ một tác vụ nào đó***.

## Lợi ích và bất lợi khi sử dụng đa luồng

### <span style="color: green">Lợi ích </span>
* Sử dụng multiple thread giúp tăng tốc các chương trình có nhiều thao tác I/O, đọc ghi dữ liệu
* Thread nhẹ hơn, tốn ít memory hơn process
* Các threads sẽ dùng chung tài nguyên => việc giao tiếp giữa các thread dễ dàng hơn

### <span style="color: red">Bất lợi </span>
* Các `CPython thread` bị hạn chế bởi các giới hạn của `Global Interpreter Lock (GIL)`
* **GIL trong CPython là cơ chế bảo vệ bộ nhớ dùng chung, do đó chỉ cho phép một thread thực thi tại một thời điểm*** ➡️  multithread  sẽ <span style="color: orange">không hiệu quả với các task cần sức mạnh của CPU, chỉ hiệu quả với các task I/O nhiều </span>.
* Do các thread chia sẻ chung tài nguyên => có thể dẫn tới race condition và data race
* Việc switch giữa các thread yêu cầu tài nguyên tính toán khá lớn => sử dụng quá nhiều thread trong một process có thể ảnh hưởng tới hiệu năng của chương trình.

# Processes
***Processes*** giống với ***threads***, có thể làm mọi thứ mà thread có thể làm.
Tuy nhiên ***processes*** không bị giới hạn thực thi bởi ***singular CPU core***.

Một *processes* bao gồm một `main primary thread`, và có thể ***spawn*** ra nhiều ***sub-threads*** con để cùng thực thi chương trình. Mỗi ***thread*** đều có register và stack riêng.

![[Pasted image 20250413091422.png]]
## Các thuộc tính của processes

Một Unix processes được tạo ra bởi OS, bao gồm các thông tin sau:
* Process ID, process group ID, user ID và group ID
* Environment
* Working directory
* Program instruction
* Registers
* Stack 
* Heap
* File descriptors
* Signal actions
* Shared libraries
* Inter-process communication - IPC tools (ví dụ như: *message queues, pipes, semaphores hoặc shared memory*)

***Lợi ích của việc sử dụng processes***:
1. Processes có thể tận dụng sức mạnh của *multi-core processors*
2. Tốt hơn multiple threads trong việc handle các *CPU-intensive tasks*
3. Tránh được giới hạn của GIL bằng việc spawning ra nhiều processes
4. Việc crash một processes sẽ ko kill tiến trình chính.

***Hạn chế của việc sử dụng processes***
1. Không thể share resources giữa các process➡️ phải tự implement một IPC riêng
2. Yêu cầu nhiều memory hơn Threads

# Multiprocessing

Trong python, có thể run code sử dụng cả ***multiple threads*** hoặc ***multiple processes***
- ***multiple threads***: tốn ít ram hơn, nhưng bị giới hạn bởi sức mạnh tính toán của 1 CPU core (do chỉ sử dụng 1 CPU core) thường dùng cho các task tốn thời gian như file I/O, network requests 
- ***multiple processes***: tốn nhiều ram hơn, nhưng có thể tận dụng sức mạnh của toàn bộ các CPU cores trên machine. sử dụng cho các task cần computation-heavy operations

Python sử dụng module `multiprocessing` để có thể tận dụng sức mạnh của toàn bộ cores và CPUs
```python
import multiprocessing

multiprocessing.cpu_count()
```
Việc sử dụng multiprocesses có thể tránh được hạn chế của Global Interpreter Lock (GIL).

Tuy nhiên các processes lại ko chia sẻ resources với nhau ➡️ tự định nghĩa cơ chế IPC giữa các processes.

# Event-driven programming

![[Pasted image 20250413093713.png]]

# Reactive programming

Reactive programming giống với event-driven, tuy nhiên thay vì dựa vào các event thì nó tập trung dựa vào data để xử lý.

Reactive programming hoạt động dựa trên một ***streams of data*** và handle mỗi khi data có sự thay đổi.

## ReactiveX - RxPy

***RxPy*** là một thư viện phổ biến trong ReactiveX framework. ***Reactive framework*** là sự kết hợp của ***observer pattern***, ***iterator pattern và functional programming***.

Chúng sẽ subscribe các ***incoming data streams*** khác nhau, tạo ra các ***observers*** để lắng nghe các events được trigger. Khi các observers được triggers, chúng sẽ chạy các đoạn code handle tương ứng.

***Bài toán ví dụ***:
Trong một datacenter, có hàng ngàn server rack, chúng ta cần theo dõi nhiệt độ của từng con server để đảm bảo server ko bị quá nóng và sẽ bị hỏng. Chúng ta sẽ setup một `RxPy program` để theo dõi liên tục (`continuous stream`) thông tin về nhiệt độ của từng con server. Trong khi `observers`, chúng ta sẽ định nghĩa một ***series of conditional events*** để listen, bất cứ khi nào có condition được thỏa mãn => handler của nó sẽ được chạy.

```python
import rx
from rx import Observable, Observer
# Tại đây định nghĩa một custom observer, có 3 method: on_next, on_error và on_completed
class TemperatureObserver(Observer):
	# Mỗi khi nhận được một temperature reading, sẽ gọi method on_next
	def on_next(self, x):
		print("Temperature is: %s degress centigrade" % x)
		if (x > 6):
			print("Warning: Temperate is Exceeding Recommended Limit")
		if (x == 9):
			print("DataCenter is shutting down. Temperature is too high")
	# Nếu nhận được một message lỗi
	def on_error(self, e):
		print("Error: %s" % e)
	def on_completed(self):
		print("All temps Read")

# Publish some fake temperature readings
xs = Observable.from_iterable(range(10))
# Subcribe to these temperature readings
d = xs.subcribe(TemperatureObserver())
```

# The limitations of Python

***Global Interpreter Lock (GIL)***: là một ***mutual exclusion lock***, giúp ngăn chặn các threads trong python code được thực thi song song. 
Lock này chỉ được ***hold bởi một thread tại một thời điểm***. Nếu một thread muốn thực thi code, nó phải ***acquire lock*** tước khi thực thi code. Khi một thread đang hold lock, các thread khác sẽ bị pending.

![[Pasted image 20250413115837.png]]
***Các thread sẽ acquire lock theo random round-robin***.

# Một số ví dụ sử dụng concurrent trong python

Với các tác vụ không cần CPU tính toán nhiều thì ta có thể sử dụng multithread
### Sequential download

```python
import urllib.request

def download_image(image_path, file_name):
	print("Download image from ", image_path)
	urllib.request.urlretrieve(image_path, file_name)

def main():
	for i in range(10):
		image_name = "temp/image-" + str(i) + ".jpg"
		download_image("https://lorempixel.com/400/200/sports", image_name)

if __name__ = '__main__':
	main()
```

### Concurrent download multithread

```python
import threading
import urllib.request
import time

def download_image(image_path, file_name):
	print("Download image from ", image_path)
	urllib.request.urlretrieve(image_path, file_name)
	print("Completed Download")

def execute_thread(i):
	image_name = "temp/image-" + str(i) + ".jpg"
	download_image("https://lorempixel.com/400/200/sports", image_name)

def main():
	start_time = time.time()
	threads = []
	# tạo ra 10 thread, và append vào mảng các threads
	for i in range(10):
		thread = threading.Thread(target=execute_thread, args=(i,))
		threads.append(thread)
		thread.start()
	# ensure tất cả các thread đã được completed
	for i in threads:
		# Đảm bảo toàn bộ các thread đều đã kết thúc thì mới process tiếp
		i.join() 
	end_time = time.time()
	total_time = end_time - start_time

if __name__ = '__main__':
	main()
```

Với các tác vụ cần sử dụng sức mạnh tính toán của CPU thì nên sử dụng multiprocess để tránh bị block ở GIL
### Sequential prime factorization

```python
import time
import random

def calculatePrimeFactors(n):
	primfac = []
	d = 2
	while d*d <= n:
		while (n % d) == 0:
			primfac.append(d)
			n //= d
		d += 1
	if n > 1:
		primfac.append(n)
	return primfac

def main():
	start = time.time()
	for i in range(10000):
		rand = random.randint(20000, 10000000)
		print(calculatePrimeFactors(rand))
	end = time.time()
	totalTime = end - start
if __name__ == '__main__':
	main()
```

### Concurrent prime factorization multiprocesses
```python
import time
import random
from multiprocessing import Process

def calculatePrimeFactors(n):
	primfac = []
	d = 2
	while d*d <= n:
		while (n % d) == 0:
			primfac.append(d)
			n //= d
		d += 1
	if n > 1:
		primfac.append(n)
	return primfac

def executeProc():
	for i in range(1000):
		rand = random.randint(20000, 10000000)
		print(calculatePrimeFactors(rand))

def main():
	start = time.time()
	procs = []
	for i in range(10):
		proc = Process(target=executeProc, args=())
		procs.append(proc)
		proc.start()
	# sử dụng .join() để chờ tới khi tất cả các process đều finish
	for proc in procs:
		proc.join()
	end = time.time()
	total_time = end - start

if __name__ == '__main__':
	main()
```