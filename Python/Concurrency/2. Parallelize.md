```table-of-contents
```

# Understanding Concurrency

Bản chất của concurrency là ***một người*** làm ***nhiều việc, và chuyển qua lại rất nhanh giữa các công việc***.

## Điểm nghẽn hiệu năng giữa hai mô hình

***Với concurrency***

 👉 Nếu bạn **áp dụng concurrency (đồng thời hóa)** cho một điểm nghẽn do **CPU** gây ra (ví dụ, tính toán nặng), thì thay vì cải thiện hiệu năng, **hiệu năng có thể giảm đi**.  
⚠️ Vì concurrency thường dùng cho các tác vụ **I/O-bound** (như chờ đọc file, truy cập mạng), không giúp ích gì nhiều khi CPU đang là điểm nghẽn.

***Với parallelism***

👉 Ngược lại, nếu bạn **dùng parallelism (xử lý song song)** cho một tác vụ mà **cần concurrency** (ví dụ như xử lý nhiều kết nối mạng không đồng bộ), thì hiệu năng cũng **có thể bị giảm**.  
⚠️ Vì parallelism thường yêu cầu chia nhỏ tác vụ và xử lý đồng thời bằng nhiều lõi CPU, nhưng lại không hiệu quả với tác vụ chủ yếu là I/O.

## Một số tính chất của concurrent systems

* ***Multiple actors*** : cả processes và threads đều là các actors độc lập, mỗi actor sẽ xử lý công việc riêng của nó. Một chương trình có nhiều processes, một process lại có nhiều threads.
* ***Shared resources***: các actors không hoạt động độc lập hoàn toàn, chúng chia sẻ các tài nguyên như: RAM, Disk, I/O device, ..... Chính vì các tài nguyên được shared ➡️ có nguy cơ xảy ra xung đột.
* ***Rules***: Có một số các quy tắc điều phối quyền truy cập để tránh lỗi khi chia sẻ tài nguyên mà tất cả các concurrent system phải tuân theo. Các rule này sẽ quy định, khi nào một actor có thể ***acquire*** và ***không thể acquire*** lock, access memory, modify state,..... Các quy tắc này đảm bảo tính nhất quán (consistency) của chương trình.

### I/O bottlenecks

***I/O bottleneck*** xảy ra khi máy tính giành quá nhiều thời gian cho việc xử lý input, output hơn là việc xử lý logic chương trình.

Web browser là một ví dụ về heavy I/O apllication. Nó dành phần lớn thời gian để chờ network request. Nếu tốc độ mà chương trình nhận được dữ liệu từ nguồn I/O ***chậm hơn*** tốc độ mà chương trình xử lý dữ liệu ➡️ ***I/O bottleneck***.

Một ví dụ khác về I/O bottleneck là web crawler.
```python
import urllib.request
import time
from bs4 import BeautifulSoup

t0 = time.time()
req = urllib.request.urlopen('http://www.example.com')
t1 = time.time()
print("Total Time To Fetch Page: {} Seconds".format(t1-t0))
soup = BeautifulSoup(req.read(), "html.parser")
for link in soup.find_all('a'):
print(link.get('href'))
t2 = time.time()
print("Total Execeution Time: {} Seconds".format)
```
Với ví dụ trên, phần lớn thời gian chương trình dùng để fetch dữ liệu. Nếu cần crawl trên nhiều trang web khác nhau ➡️ thời gian thực thi quá lâu.

<span style="font-size: 20px; font-weight:bold">Kết luận: </span> sử dụng concurrency để xử lý các bài toán về I/O bottlenecks

# Understanding parallelism

***Parallelism***: là việc thực thi 2 hoặc nhiều công việc đồng thời, trái ngược với concurrency. Parallelism sẽ thực sự xử lý 2 task cùng lúc (tại cùng một thời điểm), còn concurrency tại một thời điểm chỉ thực thi 1 task.

Để sử dụng được parallelism, chúng ta cần nhiều hơn 1 cpu core.
![[Pasted image 20250419231616.png]]
Trong thực tế, một ví dụ điển hình của việc sử dụng parallelism chính là GPU của máy tính.

## CPU-bound bottlenecks

***CPU-bound bottleneck*** trái ngược hoàn toàn với ***I/O-bound bottleneck***, chương trình dành nhiều hiệu năng cho các tác vụ tính toán => làm chậm hiệu năng.

Các ***CPU-bound*** thường xảy ra với các chương trình tính toán nặng như: xử lý ảnh, học máy, mã hóa,....
Hiệu năng của chương trình phụ thuộc vào tốc độ của CPU.

➡️ Cải thiện hiệu năng chương trình bằng việc dùng nhiều CPU core cùng lúc.

## Single-core CPUs

Single-core processor sẽ chỉ thực thi một thread tại một thời điểm.
Trong thời gian chờ (do I/O hoặc network), nó sẽ thực hiện việc switch giữa các thread (***context switch***). 
Hệ thống sẽ lưu lại toàn bộ các thông tin của thread cũ tại thời điểm đó, switch sang thread mới để thực thi. Sau đó qua lại thread cũ sẽ restore lại toàn bộ dữ liệu đã lưu để tiếp tục thực thi thread.

***Chú ý***: Khi sử dụng multiple thread, chi phí tính toán để thực hiện ***context switch*** là rất lớn, nếu không sử dụng thread hợp lý có thể làm giảm hiệu năng.

***Một số lợi ích của single-core CPUs***:
* Không yêu cầu giao thức liên lạc phức tạo giữa các multiple cores
* Sử dụng single-core CPU tốn ít điện năng hơn, phù hợp với các thiết vị IOT

***Một số bất lợi khi sử dụng single-core CPU***:
* Chương trình bị giới hạn bởi khả năng của CPU, trong các ứng dụng lớn, phức tạp có thể gây treo hệ thống.
* Nếu xử lý tác vụ quá nặng, CPU có thể bị quá nóng và bị hỏng.

### Clock rate

Một trong những hạn chế của các single-core application đó là ***clock speed of the CPU - Số clock cycles mà CPU có thể thực hiện mỗi giây***.

Định luật ***Moore*** dự đoán rằng, số lượng transitor trên mỗi con chip tăng gấp đôi sau mỗi 2 năm. Khi transitor nhỏ hơn và nhiều hơn, CPU sẽ chạy nhanh hơn (***tăng xung nhịp - clock speed***).
Hiện nay, transitor đã thu nhỏ đến mức vài nanomet, gần chạm tới giới hạn vật lý. Khi transitor quá nhỏ ➡️ ***quantum tunneling*** - electron có thể ***xuyên qua rào cản điện*** mà đang lẽ nó ko được vượt qua ➡️ transitor hoạt động không chính xác, gây rò điện, lỗi mạch.

### Time-sharing - Task scheduler

***Task scheduler*** có nhiệm vụ đảm bảo mỗi task đều có cơ hội thực thi

Ví dụ
```python
import threading
import time
import random
counter = 1
def workerA():
	global counter
	while counter < 1000:
		counter += 1
		print("Worker A is incrementing counter to {}".format(counter))
		sleepTime = random.randint(0,1)
		time.sleep(sleepTime)
def workerB():
	global counter
	while counter > -1000:
		counter -= 1
		print("Worker B is decrementing counter to {}".format(counter))
		sleepTime = random.randint(0,1)
		time.sleep(sleepTime)
def main():
	t0 = time.time()
	thread1 = threading.Thread(target=workerA)
	thread2 = threading.Thread(target=workerB)
	thread1.start()
	thread2.start()
	thread1.join()
	thread2.join()
	t1 = time.time()
	print("Execution Time {}".format(t1-t0))
if __name__ == '__main__':
	main()
```

Đoạn code trên có thể gây ra ***infinite loop*** nếu CPU switch giữa hai thread workerA và workerB ➡️ Rủi ro khi dùng chung dữ liệu.

## Multi-core processors

***Multi-core processors***: bao gồm các processing unit (core) hoạt động độc lập.
Mỗi core sẽ hoạt động theo vòng lặp sau:
1. ***Fetch***: lấy các câu lệnh từ memory của chương trình. Các câu lệnh này được xác định bởi `program counter (PC)` xác định vị trí của bước tiếp theo cần thực hiện.
2. ***Decode***: Sau khi lấy được các instruction, core sẽ convert nó sang signals để CPU có thể hiểu được
3. ***Execute***: CPU sẽ thực thi các đoạn instruction lấy được. Kết quả của việc thực thi được lưu ở các ***CPU register***.


# <span style="color: red">System architecture styles</span>

Các ***System architecture styles*** khác nhau sẽ phù hợp với từng use case khác nhau. Một số style sẽ phù hợp với các computing task hoặc scientific computing, một số khác thì phù hợp với home-computing task

## SISD - single instruction stream, single data stream

Kiến trúc này bao gồm *1 luồng datastream, 1 single unit được sử dụng để xử lý datastream đó*.
![[Pasted image 20250420091628.png]]
Đây là style kiến trúc của Single-core processors

## SIMD - single instruction stream, mutiple data stream

Kiến trúc bao gồm *nhiều luồng data stream, một luồng Instruction xử lý toàn bộ các data nhận được***
Ví dụ trong xử lý đồ họa 3D, các dữ liệu đầu vào là các vector nhiều chiều:
![[Pasted image 20250420092118.png]]

Kiến trúc này được áp dụng trong các lõi xử lý đồ họa, ví dụ trong `OpenGL graphic programming`.
![[Pasted image 20250420092332.png]]
Trong ví dụ trên, có nhiều luồng data đại diện cho các vector nhiều chiều, đồng thời có nhiều các `processing units`.

Tất các các `processing units` đều thực thi chung một `single instruction` ➡️ ***xử lý dữ liệu theo cùng một logic***.

***Lợi ích***:
* Có thể thực thi đồng thời cùng 1 logic trên nhiều dữ liệu 
* Sức mạnh tính toán sẽ tăng khi số lượng core của CPU tăng.

## MISD - multiple instruction stream, single data stream

Kiến trúc này không được sử dụng trong thực tế

## MIMD - multiple instruction streams, multiple data streams

Các core của CPU sẽ chạy song song và hoàn toàn độc lập, với luồng data input khác nhau, xử lý các tập lệnh khác nhau.
![[Pasted image 20250420093427.png]]


# <span style="color: red">Computer memory architecture styles</span>

Trong lập trình concurrency hoặc parallelism, việc tổ chức dữ liệu hợp lý để các thread hoặc process có thể access data nhanh nhất là biggest challenges.

Nếu việc access data không đủ nhanh ➡️ dẫn tới ***bottleneck*** làm giảm hiệu năng chương trình.

## UMA - Uniform Memory Access

Với kiến trúc này, tất cả các core sẽ sử dụng chung một ***memory space***.
***Mọi core đều truy cập vào bộ nhớ chung với tốc độ như nhau***, bất kể core đó có nằm gần hay xa RAM thì tốc độ truy cập vào bộ nhớ RAM đều như nhau.

![[Pasted image 20250420094831.png]]
Mỗi processor sẽ được ***kết nối với bus***. ***Bus*** là thành phần trung gian chịu trách nhiệm truy cập bộ nhớ thay cho các CPU.
CPU muốn đọc/ghi đều phải gửi qua ***Bus***.

***Ưu điểm***:
* Các CPU có thể truy cập RAM với tốc độ như nhau
* Đồng nhất dữ liệu
* Thiết kế đơn giản

***Nhược điểm***: 
Khi có nhiều CPU
*  Tất các các CPU đều phải dùng chung một bus
* Gây ra tắc nghẽn đường truyền khi tất các CPU đều gửi request vào bus ➡️ Giảm hiệu năng hệ thống.

## NUMA - Non-uniform Memory Access

![[Pasted image 20250420105723.png]]
Với kiến trúc này, mỗi process sẽ có memory space riêng, I/O riêng, và sẽ giao tiếp với nhau qua ***interconnection network***.

***Lợi ích chính của NUMA***:
* NUMA machine có thể dễ dàng scale hơn UMA

***Hạn chế của NUMA***:
* Tốc độ truy cập vào memory của CPU phụ thuộc vào vị trí của memory, nếu memory ở local ⇒ truy cập nhanh, nếu memory ở xa ⇒ mất thời gian để truy xuất memory.
* Các processor phải quan sát sự thay đổi được tạo ra bởi các processor khác, thời gian dành cho việc này tăng lên khi số lượng processor tăng.
