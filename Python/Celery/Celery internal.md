```table-of-contents
```

![[image.webp]]
# Celery l√† g√¨ ?

`Task queues` ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ m·ªôt c∆° ch·∫ø ƒë·ªÉ `distribute work` th√¥ng qua c√°c threads ho·∫∑c c√°c machines.
***Celery*** giao ti·∫øp th√¥ng qua c√°c messages, s·ª≠ d·ª•ng m·ªôt ***broker*** ƒë·ªÉ l√†m trung gian gi·ªØa clients v√† workers.
M·ªôt ***Celery system*** c√≥ th·ªÉ bao g·ªìm nhi·ªÅu workers v√† nhi·ªÅu brokers ƒë·ªÉ duy tr√¨ HA v√† horizontal scaling.

# T·∫°i sao n√™n s·ª≠ d·ª•ng Celery

 * ***Task queue management***: celery gi√∫p qu·∫£n l√Ω c√°c background jobs, offload c√°c long running task ƒë·ªÉ tr√°nh delay user response
 * ***Asynchronous Processing***: Celery c√≥ th·ªÉ th·ª±c thi c√°c task m·ªôt c√°c b·∫•t ƒë·ªìng b·ªô, th·ª±c thi c√°c task m√† kh√¥ng block main application
 * ***Distributed Task Execution***: c√≥ th·ªÉ scale horizontally th√¥ng qua nhi·ªÅu worker ‚áí c√≥ th·ªÉ x·ª≠ l√Ω ƒë∆∞·ª£c l∆∞·ª£ng l·ªõn task.
 * ***Scheduled Jobs***: S·ª≠ d·ª•ng celery ƒë·ªÉ l·∫≠p l·ªãch cho c√°c task ch·∫°y h·∫±ng ng√†y.
 * ***Reliability***: Celery gi√∫p ch·∫Øc ch·∫Øn c√°c task s·∫Ω ƒë∆∞·ª£c th·ª±c thi, s·∫Ω retry khi c√≥ failure v√† cung c·∫•p monitoring

# Ki·∫øn tr√∫c c∆° b·∫£n c·ªßa Celery

![[Pasted image 20250505062023.png]]

## 1. Transport

***Celery transport*** ch·ªãu tr√°ch nhi·ªám ***l∆∞u tr·ªØ c√°c task argument v√† c√°c task states***. Ngo√†i ra c√≤n l∆∞u th√™m m·ªôt s·ªë c√°c th√¥ng tin kh√°c c·ªßa task v√≠ d·ª•: name, uuid, runtime, no of retries,...

M·ªôt s·ªë lo·∫°i ***celery transport*** ph·ªï bi·∫øn:
* Redis
* RabbitMQ
* Kafka

## 2. Task Serialization/Deserialization

***Task serialization v√† deserialization*** ch·ªãu tr√°ch nhi·ªám convert c√°c task th√†nh c√°c format chu·∫©n ƒë·ªÉ c√≥ th·ªÉ g·ª≠i qua t·ª´ng lo·∫°i broker, v√† c√°c worker c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c y√™u c·∫ßu c·ªßa c√°c task.
Hai quy tr√¨nh tr√™n gi√∫p ƒë·∫£m b·∫£o c√°c task ƒë∆∞·ª£c g·ª≠i, l∆∞u tr·ªØ v√† th·ª±c thi trong h·ªá th·ªëng ph√¢n t√°n.

M·ªôt v√†i lo·∫°i ***task serialization format*** th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng:
* JSON
* Pickle
* YAML
* Msgpack

## 3. Consumer / Worker

***Consumer / Worker*** s·∫Ω nh·∫≠n task input t·ª´ `transport`, x·ª≠ l√Ω c√°c task. ***X·ª≠ l√Ω tasks*** c√≥ nghƒ© l√† th·ª±c thi m·ªôt function v·ªõi `paramenters` ƒë∆∞·ª£c g·ª≠i k√®m theo.
Task s·∫Ω k·∫øt th√∫c khi function ƒë√≥ ch·∫°y xong ho·∫∑c failed.

Khi m·ªôt task b·ªã failed, `Celery worker` s·∫Ω tr·∫£ v·ªÅ message cho `transport`.
`transport` s·∫Ω tƒÉng s·ªë l·∫ßn retries c·ªßa task ƒë√≥ l√™n, v√† worker s·∫Ω ch·∫°y l·∫°i task ƒë√≥ (***c∆° ch·∫ø retries***)

```python
from celery import shared_task

@shared_task
def adder(num1, num2):
	sleep(2)
	return num1 + num2
```

## 4. Producer

***Producer*** c√≥ th·ªÉ l√† b·∫•t k·ª≥ th√†nh ph·∫ßn n√†o trong h·ªá th·ªëng, g·ªçi m·ªôt t√°c v·ª• Celery. N√≥ c√≥ th·ªÉ l√† m·ªôt h√†m trong view, model method, m·ªôt l·ªãch ƒë·ªãnh k·ª≥ Celery beat, ho·∫∑c m·ªôt script python.

***Producer*** s·∫Ω call c√°c `celery task` k√®m theo c√°c `argument` t∆∞∆°ng ·ª©ng c·ªßa task ƒë√≥, s·ª≠ d·ª•ng `.delay()`. Khi g·ªçi t·ªõi `.delay()`, task s·∫Ω ƒë∆∞·ª£c g·ª≠i t·ªõi h√†ng ƒë·ª£i broker

```python
from .tasks import adder

def run():
    res = adder.delay(num1=12, num2=13)
    return res
```
- `adder.delay(...)` s·∫Ω **kh√¥ng ch·∫°y ngay l·∫≠p t·ª©c**, m√† g·ª≠i task t·ªõi Celery queue.
- M·ªôt **worker Celery ƒëang ch·∫°y** s·∫Ω nh·∫≠n task n√†y v√† x·ª≠ l√Ω n√≥ ·ªü n·ªÅn.
- `res` l√† m·ªôt `AsyncResult` object, b·∫°n c√≥ th·ªÉ d√πng `.get()` ƒë·ªÉ l·∫•y k·∫øt qu·∫£ n·∫øu c·∫ßn, v√≠ d·ª• `res.get()`.

## 5. M·ªôt s·ªë component kh√°c c·ªßa celery

### Celery beat

***Celery beat*** l√† m·ªôt ***scheduler***, n√≥ s·∫Ω l·∫≠p l·ªãch cho c√°c task ƒë·ªãnh k·ª≥ trong m·ªôt kho·∫£ng th·ªùi gian v√† ƒë∆∞·ª£c th·ª±c thi b·ªüi m·ªôt worker n√†o ƒë√≥ ƒëang available.
 ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l·∫≠p l·ªãch cho c√°c task ch·∫°y ƒë·ªãnh k·ª≥.
```python
# tasks.py

from celery import Celery
from celery.schedules import crontab

app = Celery('my_app')

@app.task
def periodic_task():
    print("Running periodic task!")

app.conf.beat_schedule = {
    'run-every-hour': {
        'task': 'periodic_task',
        'schedule': crontab(minute=0, hour='*'),  # Executes every hour
    },
}
```

```bash
celery -A your_project beat --loglevel=info
```

### Result backend

***Result backend*** l√† n∆°i l∆∞u tr·ªØ to√†n b·ªô c√°c ***tasks result*** ƒë√£ ƒë∆∞·ª£c th·ª±c thi. N√≥ l∆∞u nhi·ªÅu th√¥ng tin kh√°c c·ªßa task bao g·ªìm:
1. ***Task result*** : l∆∞u k·∫øt qu·∫£ tr·∫£ v·ªÅ c·ªßa m·ªôt task ƒë∆∞·ª£c ƒë∆∞·ª£c th·ª±c thi
2. ***Task state***: l∆∞u l·∫°i c√°c tr·∫°ng th√°i c·ªßa task nh∆∞ PENDING, STARTED, SUCCESS, FAILURE, RETRY,...
3. ***Task chaining information***: m·ªôt s·ªë th√¥ng tin kh√°c v√≠ d·ª• nh∆∞ l√† root task c·ªßa task hi·ªán t·∫°i, .....

M·ªôt v√†i celery result backend ph·ªï bi·∫øn:
1. Memory: l∆∞u c√°c th√¥ng tin trong memory c·ªßa worker
2. Redis
3. RabbitMQ
4. Django database

### Celery monitoring with flower


# Celery concurrency

***Celery concurrency*** cho ph√©p m·ªôt worker x·ª≠ l√Ω nhi·ªÅu task c√πng l√∫c b·∫±ng c√°ch s·ª≠ d·ª•ng nhi·ªÅu ti·∫øn tr√¨nh (multiprocessing) ho·∫∑c nhi·ªÅu lu·ªìng (multithreading).
D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë m√¥ h√¨nh Concurrency trong celery
## M√¥ h√¨nh Pre-fork (m·∫∑c ƒë·ªãnh)

ƒê√¢y l√† m√¥ h√¨nh concurrency m·∫∑c ƒë·ªãnh trong celery, n√≥ t·∫°o ra nhi·ªÅu ti·∫øn tr√¨nh con, m·ªói ti·∫øn tr√¨nh s·∫Ω x·ª≠ l√Ω m·ªôt task ri√™ng bi·ªát.

∆Øu ƒëi·ªÉm: ·ªïn ƒë·ªãnh, tr√°nh GIL trong python, ph√π h·ª£p cho c√°c t√°c v·ª•  CPU-bound ho·∫∑c h·ªón h·ª£p

```bash
celery -A your_app worker --concurrency=4
```
‚û°Ô∏è Worker s·∫Ω d√πng 4 process ƒë·ªÉ x·ª≠ l√Ω c√°c task song song

## M√¥ h√¨nh eventlet v√† getevent

### üî∑ 1. `eventlet` v√† `gevent` l√† g√¨?
- ƒê√¢y l√† **c√°c th∆∞ vi·ªán asynchronous I/O** (x·ª≠ l√Ω I/O b·∫•t ƒë·ªìng b·ªô).
- Thay v√¨ t·∫°o nhi·ªÅu ti·∫øn tr√¨nh nh∆∞ pre-fork, ch√∫ng d√πng c√°i g·ªçi l√† **"greenlet"** (lu·ªìng nh·∫π).
- Ph√π h·ª£p cho c√°c task **ch·ªù I/O nhi·ªÅu** nh∆∞:
    - G·ªçi API HTTP
    - Truy v·∫•n CSDL
    - ƒê·ªçc ghi file, socket...

> üéØ ∆Øu ƒëi·ªÉm: C√≥ th·ªÉ x·ª≠ l√Ω **h√†ng trƒÉm ho·∫∑c h√†ng ngh√¨n task song song** m√† **kh√¥ng t·ªën nhi·ªÅu RAM/CPU** nh∆∞ pre-fork.

### üî∂ 2. H·∫°n ch·∫ø khi d√πng `eventlet` ho·∫∑c `gevent`

Khi b·∫°n **chuy·ªÉn t·ª´ pre-fork sang eventlet ho·∫∑c gevent**, m·ªôt s·ªë t√≠nh nƒÉng trong Celery **s·∫Ω kh√¥ng c√≤n ho·∫°t ƒë·ªông**, v√≠ d·ª•:
#### ‚ùå `soft_timeout` b·ªã v√¥ hi·ªáu h√≥a

- `soft_timeout`: l√† timeout m·ªÅm c·ªßa task ‚Äî task s·∫Ω b·ªã **c·∫£nh b√°o** (th∆∞·ªùng b·∫±ng `SoftTimeLimitExceeded`) ƒë·ªÉ d·ª´ng l·∫°i.
- Trong `eventlet` v√† `gevent`, Celery **kh√¥ng th·ªÉ can thi·ªáp "m·ªÅm"** v√†o task ƒëang ch·∫°y v√¨ kh√¥ng c√≥ process th·∫≠t ‚Üí n√™n `soft_timeout` **b·ªã v√¥ hi·ªáu h√≥a √¢m th·∫ßm**.
#### ‚ùå `max_tasks_per_child` c≈©ng kh√¥ng ho·∫°t ƒë·ªông

- T√≠nh nƒÉng n√†y d√πng trong pre-fork ƒë·ªÉ t·ª± ƒë·ªông **k·∫øt th√∫c worker sau khi ch·∫°y X task**, nh·∫±m tr√°nh memory leak.
- V√¨ `eventlet/gevent` **ch·ªâ c√≥ 1 process**, kh√¥ng c√≥ child process ‚Üí t√≠nh nƒÉng n√†y **kh√¥ng c√≥ t√°c d·ª•ng**.
### ‚ö†Ô∏è C·∫£nh b√°o quan tr·ªçng

> Khi b·∫°n d√πng `--pool=eventlet` ho·∫∑c `--pool=gevent`, Celery **kh√¥ng b√°o l·ªói r√µ r√†ng** n·∫øu c√°c t√≠nh nƒÉng nh∆∞ `soft_timeout` hay `max_tasks_per_child` b·ªã v√¥ hi·ªáu h√≥a ‚Üí r·∫•t d·ªÖ khi·∫øn b·∫°n **nghƒ© r·∫±ng ch√∫ng v·∫´n ƒëang ho·∫°t ƒë·ªông**, trong khi th·ª±c t·∫ø th√¨ kh√¥ng.

## M√¥ h√¨nh Solo

C√°c task s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω tu·∫ßn t·ª± trong main thread c·ªßa task. M√¥ h√¨nh n√†y ph√π h·ª£p ƒë·ªÉ ch·∫°y c√°c task ƒë∆°n gi·∫£n, lightweight task. Ngo√†i ra c√≥ th·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh n√†y ƒë·ªÉ debug logic task. Tuy nhi√™n m√¥ h√¨nh n√†y kh√¥ng th·ªÉ scale v·ªõi s·ªë l∆∞·ª£ng l·ªõn.

## M√¥ h√¨nh s·ª≠ d·ª•ng multithreads

Celery c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c `threads` ƒë·ªÉ th·ª±c thi c√°c task song song thay v√¨ s·ª≠ d·ª•ng `processes` nh∆∞ m√¥ h√¨nh pre-fork.

M√¥ h√¨nh thread-base n√†y s·ª≠ d·ª•ng `ThreadPoolExecutor` t·ª´ `concurrent.futures`, kh√¥ng c·∫ßn c√†i th√™m th∆∞ vi·ªán ngo√†i.
Worker ***ch·ªâ ch·∫°y m·ªôt processs*** v√† ***c√°c task s·∫Ω ƒë∆∞·ª£c th·ª±c thi trong c√°c thread c·ªßa process ƒë√≥***. C√°c thread c√πng chia s·∫ª b·ªô nh·ªõ.

Threads r·∫•t ph√π h·ª£p cho c√°c **task I/O-bound**, t·ª©c l√† c√°c task d√†nh nhi·ªÅu th·ªùi gian **ch·ªù ƒë·ª£i** thay v√¨ x·ª≠ l√Ω t√≠nh to√°n:
- G·ªçi HTTP API
- ƒê·ªçc/ghi file
- Giao ti·∫øp m·∫°ng

‚Üí Trong l√∫c m·ªôt thread ƒëang ch·ªù I/O, c√°c thread kh√°c v·∫´n c√≥ th·ªÉ l√†m vi·ªác.

### ‚ö†Ô∏è Nh∆∞·ª£c ƒëi·ªÉm v√† c·∫£nh b√°o:

- V√¨ c√°c thread d√πng **chung v√πng nh·ªõ**, n√™n:
    - D·ªÖ x·∫£y ra **race condition** n·∫øu nhi·ªÅu thread c√πng s·ª≠a ƒë·ªïi m·ªôt bi·∫øn.
    - N·∫øu kh√¥ng ki·ªÉm so√°t k·ªπ, c√≥ th·ªÉ g√¢y **deadlock**.

‚Üí C·∫ßn c·∫©n tr·ªçng n·∫øu task c√≥ c·∫≠p nh·∫≠t d·ªØ li·ªáu d√πng chung (bi·∫øn to√†n c·ª•c, cache, ƒë·ªëi t∆∞·ª£ng singleton...).

 üî∏ **"GIL can create further problems"**
- Python (CPython) c√≥ **Global Interpreter Lock (GIL)**, ch·ªâ cho ph√©p **m·ªôt thread th·ª±c thi Python bytecode t·∫°i m·ªôt th·ªùi ƒëi·ªÉm**.
- V·ªõi **CPU-bound task**, GIL l√†m threads **kh√¥ng th·ª±c s·ª± ch·∫°y song song**, g√¢y ngh·∫Ωn hi·ªáu nƒÉng.
‚Üí V√¨ th·∫ø, thread-based **kh√¥ng ph√π h·ª£p** cho c√°c t√°c v·ª• n·∫∑ng v·ªÅ t√≠nh to√°n.

---
# C·∫•u h√¨nh worker pool th√¥ng qua ENV

## C·∫•u h√¨nh Celery limits 

### üïí 1. **Soft Time Limit** ‚Äî "gi·ªõi h·∫°n m·ªÅm"

- l√† th·ªùi gian t·ªëi ƒëa (t√≠nh b·∫±ng gi√¢y) m√† task **n√™n ƒë∆∞·ª£c ho√†n th√†nh**.  
    Khi h·∫øt th·ªùi gian n√†y, Celery **g·ª≠i m·ªôt c·∫£nh b√°o** d∆∞·ªõi d·∫°ng **exception**: `SoftTimeLimitExceeded`.
    
- Task c√≥ th·ªÉ **b·∫Øt exception n√†y** ƒë·ªÉ:
    - Th·ª±c hi·ªán d·ªçn d·∫πp (cleanup)
    - L∆∞u tr·∫°ng th√°i t·∫°m th·ªùi
    - Ghi log
    - Tho√°t m·ªôt c√°ch "√™m ƒë·∫πp"

```python
from celery.exceptions import SoftTimeLimitExceeded

@shared_task(soft_time_limit=5)
def long_task():
    try:
        do_something()
    except SoftTimeLimitExceeded:
        cleanup()
        return "Stopped early"

```


### üí£ 2. **Hard Time Limit** ‚Äî "gi·ªõi h·∫°n c·ª©ng"

- Th·ªùi gian t·ªëi ƒëa tuy·ªát ƒë·ªëi m√† task **ph·∫£i k·∫øt th√∫c**. N·∫øu task v∆∞·ª£t qu√° gi·ªõi h·∫°n n√†y, n√≥ s·∫Ω b·ªã **kill ngay l·∫≠p t·ª©c**.
    
- N·∫øu v∆∞·ª£t qu√° gi·ªõi h·∫°n th·ªùi gian n√†y:
    - Celery g·ª≠i t√≠n hi·ªáu `SIGTERM` ho·∫∑c `SIGKILL` ƒë·∫øn process ƒëang ch·∫°y task.
    - Kh√¥ng c√≥ c∆° h·ªôi d·ªçn d·∫πp, x·ª≠ l√Ω l·ªói hay l∆∞u tr·∫°ng th√°i g√¨ c·∫£.
    - Th∆∞·ªùng ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒë·∫£m b·∫£o task **kh√¥ng bao gi·ªù ch·∫°y v∆∞·ª£t qu√° m·ªôt ng∆∞·ª°ng nguy hi·ªÉm**.

### ‚è±Ô∏è **Quan h·ªá gi·ªØa soft v√† hard time limit**

> **Soft limit lu√¥n ƒë∆∞·ª£c ki·ªÉm tra tr∆∞·ªõc hard limit.**

- B·∫°n c√≥ th·ªÉ thi·∫øt l·∫≠p c·∫£ hai c√πng l√∫c, v√≠ d·ª•:
```python
@shared_task(soft_time_limit=10, time_limit=15)
def some_task():
    ...
```

‚Üí Task n√†y:
- C√≥ **5 gi√¢y** ƒë·ªÉ x·ª≠ l√Ω sau khi b·ªã c·∫£nh b√°o soft timeout.
- N·∫øu sau 15 gi√¢y v·∫´n ch∆∞a xong, s·∫Ω b·ªã **kill ngay l·∫≠p t·ª©c**.

| Thu·ªôc t√≠nh             | Soft Time Limit                         | Hard Time Limit                         |
| ---------------------- | --------------------------------------- | --------------------------------------- |
| M·ª•c ƒë√≠ch               | C·∫£nh b√°o ƒë·ªÉ task t·ª± tho√°t               | C∆∞·ª°ng b·ª©c d·ª´ng task                     |
| C√°ch x·ª≠ l√Ω             | Raise exception (SoftTimeLimitExceeded) | G·ª≠i `SIGTERM` / `SIGKILL`               |
| C√≥ cleanup ƒë∆∞·ª£c kh√¥ng? | ‚úÖ C√≥                                    | ‚ùå Kh√¥ng                                 |
| Th∆∞·ªùng d√πng khi n√†o?   | Cho ph√©p task d·ªçn d·∫πp an to√†n           | NgƒÉn task ch·∫°y qu√° l√¢u/l·ªói nghi√™m tr·ªçng |

## Celery task configuration ([tham kh·∫£o](https://github.dev/celery/celery/blob/main/celery/app/task.py))

|Task Configuration|Description|Default Value|Notes|
|---|---|---|---|
|max_retries|Maximum number of retries before giving up|3|If set to None, it will never stop retrying|
|default_retry_delay|Default time in seconds before a retry|180 (3 minutes)|Determines wait time between retries|
|rate_limit|Rate limit for this task type|None (no rate limit)|Examples: ‚Äò100/s‚Äô, ‚Äò100/m‚Äô, ‚Äò100/h‚Äô|
|ignore_result|If enabled, worker won‚Äôt store task state and return values|None|Defaults to task_ignore_result setting|
|time_limit|Hard time limit for task execution|None|Defaults to task_time_limit setting|
|serializer|Serializer that will be used|json|json, pickle|
|soft_time_limit|Refer to time limits|:setting:`task_soft_time_limit`||

Example 1 (kh√¥ng n√™n s·ª≠ d·ª•ng)
```python
from celery import shared_task
from celery.exceptions import SoftTimeLimitExceeded


@shared_task(
    max_retries=3,                     # Maximum retries
    default_retry_delay=180,            # Default retry delay (in seconds
    rate_limit=None,                    # No rate limit
    ignore_result=False,                # Store task state and result
    time_limit=None,                    # No hard time limit
    soft_time_limit=None,               # No soft time limit
    serializer='json'                   # Use JSON for serialization
)
def example_shared_task(*args, **kwargs):
    try:
        # Task logic here
        print(f"Processing task with args: {args} and kwargs: {kwargs}")
        # Simulate long processing task
    except SoftTimeLimitExceeded:
        print("Task exceeded the soft time limit")
        # Handle cleanup if necessary
```

DRY code (DONT REPEAT YOUR SELF)

```python
class BaseTaskWithRetry(Task):
    autoretry_for = (Exception,)
    retry_kwargs = {"max_retries": 5}
    retry_backoff = True
    retry_backoff_max = 60 * 5  # 5 minutes
    retuy_jitter = True

    def on_failure(self, exc, task_id, args, kwargs, einfo):
        super().on_failure(exc, task_id, args, kwargs, einfo)
        self.retry(exc=exc, countdown=60 * 5)



class BaseFor10HoursTask(Task):
    autoretry_for = (Exception,)
    retry_kwargs = {"max_retries": 10}
    retry_backoff = True
    retry_backoff_max = 60 * 60 * 10  # 10 hours
    retuy_jitter = True


    def on_failure(self, exc, task_id, args, kwargs, einfo):
        super().on_failure(exc, task_id, args, kwargs, einfo)
        self.retry(exc=exc, countdown=60 * 60 * 10)



class BaseFor24HoursTask(Task):
    autoretry_for = (Exception,)
    retry_kwargs = {"max_retries": 60}
    retry_backoff = True
    retry_backoff_max = 60 * 60 * 24  # 24 hours
    retuy_jitter = True


    def on_failure(self, exc, task_id, args, kwargs, einfo):
        super().on_failure(exc, task_id, args, kwargs, einfo)
        self.retry(exc=exc, countdown=60 * 60 * 24)

```